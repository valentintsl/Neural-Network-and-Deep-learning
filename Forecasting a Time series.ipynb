{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Forecasting a Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to forecast the value at the next time step\n",
    "\n",
    "Several examples of Time series :\n",
    "- Daily temperature of a city\n",
    "- Company's financial health\n",
    "- Stock market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    \"\"\"Generate a time series\"\"\"\n",
    "    #Create 4 arrays of (batch_size) rows\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    #Time is an array of evenly spaced times between 0 and 1\n",
    "    time = np.linspace(0,1, n_steps)\n",
    "    \n",
    "    series = 0.5* np.sin((time - offsets1)* (freq1*10 + 10))#wave 1\n",
    "    series += 0.4 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n",
    "    series += 0.3 * (np.random.rand(batch_size, n_steps) - 0.5) # + noise\n",
    "    \n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size creates as many time series as requested each of length n_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X_trains : 7000 times series [7000,50,1]\n",
    "- X_valid : 2000 time series [2000, 50, 1]\n",
    "- X_test : 1000 time series [1000, 50, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps +1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline metrics : Let's test with a fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.1099 - val_loss: 0.0456\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 928us/step - loss: 0.0399 - val_loss: 0.0349\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 949us/step - loss: 0.0334 - val_loss: 0.0315\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 973us/step - loss: 0.0304 - val_loss: 0.0294\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 922us/step - loss: 0.0281 - val_loss: 0.0279\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 0s 929us/step - loss: 0.0265 - val_loss: 0.0260\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 0s 966us/step - loss: 0.0254 - val_loss: 0.0250\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 0s 991us/step - loss: 0.0243 - val_loss: 0.0242\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 922us/step - loss: 0.0234 - val_loss: 0.0235\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 0s 933us/step - loss: 0.0227 - val_loss: 0.0228\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 941us/step - loss: 0.0223 - val_loss: 0.0222\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 0s 936us/step - loss: 0.0217 - val_loss: 0.0217\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.0219\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 0s 968us/step - loss: 0.0211 - val_loss: 0.0213\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 0s 991us/step - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 936us/step - loss: 0.0206 - val_loss: 0.0211\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 946us/step - loss: 0.0205 - val_loss: 0.0208\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 940us/step - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 0s 928us/step - loss: 0.0203 - val_loss: 0.0203\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 945us/step - loss: 0.0202 - val_loss: 0.0204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e9497e9c8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = [50,1]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss = 'mse', optimizer='adam')\n",
    "model.fit(X_train,y_train, epochs = 20, validation_data=(X_valid, y_valid), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain an MSE of about 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can beat that with a simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.2750 - val_loss: 0.1906\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.1666 - val_loss: 0.1383\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.1326 - val_loss: 0.1167\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.1135 - val_loss: 0.1005\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0990 - val_loss: 0.0882\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0876 - val_loss: 0.0784\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0788 - val_loss: 0.0710\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0716 - val_loss: 0.0650\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0659 - val_loss: 0.0601\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0612 - val_loss: 0.0562\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0574 - val_loss: 0.0531\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0543 - val_loss: 0.0505\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0517 - val_loss: 0.0484\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0497 - val_loss: 0.0467\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0480 - val_loss: 0.0454\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0467 - val_loss: 0.0444\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0456 - val_loss: 0.0436\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0448 - val_loss: 0.0430\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0443 - val_loss: 0.0426\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0438 - val_loss: 0.0423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e9d28b608>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    #We don't need to specify the length of the inpu sequences, sin a RNN can process any number of time steps\n",
    "    keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])\n",
    "model.compile(loss = 'mse', optimizer='adam')\n",
    "model.fit(X_train,y_train, epochs = 20, validation_data=(X_valid, y_valid), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to add more recurrent layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.0533 - val_loss: 0.0274\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0252 - val_loss: 0.0247\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 0.0235 - val_loss: 0.0248\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0228 - val_loss: 0.0230\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 4s 18ms/step - loss: 0.0221 - val_loss: 0.0217\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0218 - val_loss: 0.0252\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 0.0214 - val_loss: 0.0214\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0208 - val_loss: 0.0221\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0204 - val_loss: 0.0203\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0197 - val_loss: 0.0195\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0195 - val_loss: 0.0205\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0190 - val_loss: 0.0189\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0187 - val_loss: 0.0197\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0185 - val_loss: 0.0187\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0182 - val_loss: 0.0190\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0180 - val_loss: 0.0182\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0174 - val_loss: 0.0164\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0172 - val_loss: 0.0170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e94b6e208>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    #return_sequences = True will output a 3D array containing all time steps\n",
    "    keras.layers.SimpleRNN(20, return_sequences = True, input_shape=[None,1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = 'mse', optimizer='adam')\n",
    "model.fit(X_train,y_train, epochs = 20, validation_data=(X_valid, y_valid), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
